{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç’°å¢ƒã‚’æº–å‚™ã—ã‚ˆã†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã¾ãšã€Semantic Kernelã¨å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèªã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -qU semantic-kernel python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.23.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€Azure OpenAI Serviceã®ã‚­ãƒ¼æƒ…å ±ã‚’ä¿å­˜ã—ã¦ã„ã‚‹ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n",
    "`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€æ¬¡ã®ã‚ˆã†ãªè¨­å®šã‚’è¨˜è¿°ã—ã¾ã™ã€‚\n",
    "\n",
    "```bash\n",
    "SK_AZURE_OPENAI_DEPLOYMENT_NAME=***\n",
    "SK_AZURE_OPENAI_API_KEY=***\n",
    "SK_AZURE_OPENAI_ENDPOINT=***\n",
    "SK_AZURE_OPENAI_API_VERSION=***\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã“ã®æƒ…å ±ã‚’ã‚³ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¿ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Callingã‚’ä½¿ã£ã¦ä¼šè©±ã™ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernelï¼ˆã‚«ãƒ¼ãƒãƒ«ï¼‰ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ\n",
    "\n",
    "ã¾ãšã¯ã€Semantic Kernel ã®ä¸­å¿ƒã¨ãªã‚‹ã‚¯ãƒ©ã‚¹ `Kernel` ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIã‚µãƒ¼ãƒ“ã‚¹ï¼ˆAzure OpenAI Serviceï¼‰ã‚’è¨­å®šã™ã‚‹\n",
    "\n",
    "Semantic Kernel ã§ã¯ã€ã•ã¾ã–ã¾ãª AI ã‚µãƒ¼ãƒ“ã‚¹ã‚’ç™»éŒ²ã—ã¦ä½¿ç”¨ã§ãã¾ã™ã€‚<br/>\n",
    "ã“ã“ã§ã¯ Azure OpenAI Service ã® GPT-4o ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ã€[Chat Completion API](https://learn.microsoft.com/ja-jp/azure/ai-services/openai/how-to/chatgpt)ã‚’ä½¿ã†ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "service_id = None\n",
    "chat_completion_service = AzureChatCompletion(\n",
    "    deployment_name = os.getenv(\"SK_AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_key = os.getenv(\"SK_AZURE_OPENAI_API_KEY\"),\n",
    "    endpoint = os.getenv(\"SK_AZURE_OPENAI_ENDPOINT\"), \n",
    "    api_version = os.getenv(\"SK_AZURE_OPENAI_API_VERSION\"), \n",
    "    service_id = service_id,\n",
    ")\n",
    "kernel.add_service(chat_completion_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä½œæˆã™ã‚‹\n",
    "\n",
    "ä¼šè©±ã®å±¥æ­´ã‚’æ‰±ã†ãŸã‚ã€ChatHistory ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã‚³ã‚¢ãƒ¼é–¢æ•°ã‚’ç™»éŒ²ã™ã‚‹\n",
    "\n",
    "Function Calling ã®å€™è£œã¨ã—ã¦ä½¿ãˆã‚‹ ã‚³ã‚¢ãƒ¼é–¢æ•° ã‚’ç™»éŒ²ã—ã¾ã™ã€‚<br/>\n",
    "ä»Šå›ã¯ã€Semantic Kernel ãŒæ¨™æº–ã§ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ 2 ã¤ã®é–¢æ•°ï¼ˆMathPlugin / TimePluginï¼‰ã‚’ä¾‹ã¨ã—ã¦ä½¿ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='time', description=None, functions={'date': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='date', plugin_name='time', description='Get the current date.', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B007FFB0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163AEE40620>, method=<bound method TimePlugin.date of TimePlugin()>, stream_method=None), 'date_matching_last_day_name': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='date_matching_last_day_name', plugin_name='time', description='Get the date of the last day matching the supplied week day name in English.', parameters=[KernelParameterMetadata(name='day_name', description=None, default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CF590>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CF710>, method=<bound method TimePlugin.date_matching_last_day_name of TimePlugin()>, stream_method=None), 'day': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='day', plugin_name='time', description='Get the current day', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CF4D0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CF560>, method=<bound method TimePlugin.day of TimePlugin()>, stream_method=None), 'dayOfWeek': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='dayOfWeek', plugin_name='time', description='Get the current day of the week', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CF650>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CF5F0>, method=<bound method TimePlugin.day_of_week of TimePlugin()>, stream_method=None), 'days_ago': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='days_ago', plugin_name='time', description='Get the date of offset from today by a provided number of days', parameters=[KernelParameterMetadata(name='days', description=None, default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CF500>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CF620>, method=<bound method TimePlugin.days_ago of TimePlugin()>, stream_method=None), 'hour': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='hour', plugin_name='time', description='Get the current hour', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CF530>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CEFF0>, method=<bound method TimePlugin.hour of TimePlugin()>, stream_method=None), 'hourNumber': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='hourNumber', plugin_name='time', description='Get the current hour number', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CF020>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CEFC0>, method=<bound method TimePlugin.hour_number of TimePlugin()>, stream_method=None), 'iso_date': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='iso_date', plugin_name='time', description='Get the current date in iso format.', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CEF90>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CEF00>, method=<bound method TimePlugin.iso_date of TimePlugin()>, stream_method=None), 'minute': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='minute', plugin_name='time', description='Get the current minute', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CEF30>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CEE10>, method=<bound method TimePlugin.minute of TimePlugin()>, stream_method=None), 'month': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='month', plugin_name='time', description='Get the current month', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CEDB0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CEED0>, method=<bound method TimePlugin.month of TimePlugin()>, stream_method=None), 'month_number': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='month_number', plugin_name='time', description='Get the current month number', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CEDE0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CEEA0>, method=<bound method TimePlugin.month_number of TimePlugin()>, stream_method=None), 'now': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='now', plugin_name='time', description='Get the current date and time in the local time zone', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CEE40>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CED80>, method=<bound method TimePlugin.now of TimePlugin()>, stream_method=None), 'second': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='second', plugin_name='time', description='Get the seconds on the current minute', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CE0F0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CE120>, method=<bound method TimePlugin.second of TimePlugin()>, stream_method=None), 'time': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='time', plugin_name='time', description='Get the current time in the local time zone', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CE0C0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CE090>, method=<bound method TimePlugin.time of TimePlugin()>, stream_method=None), 'timeZoneName': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='timeZoneName', plugin_name='time', description='Get the current time zone name', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CE030>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CE060>, method=<bound method TimePlugin.time_zone_name of TimePlugin()>, stream_method=None), 'timeZoneOffset': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='timeZoneOffset', plugin_name='time', description='Get the current time zone offset', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CDF40>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CDFA0>, method=<bound method TimePlugin.time_zone_offset of TimePlugin()>, stream_method=None), 'today': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='today', plugin_name='time', description='Get the current date.', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CE000>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CDFD0>, method=<bound method TimePlugin.today of TimePlugin()>, stream_method=None), 'utcNow': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='utcNow', plugin_name='time', description='Get the current date and time in UTC', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CDF10>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CDF70>, method=<bound method TimePlugin.utc_now of TimePlugin()>, stream_method=None), 'year': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='year', plugin_name='time', description='Get the current year', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CDEE0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x00000163B00CDC70>, method=<bound method TimePlugin.year of TimePlugin()>, stream_method=None)})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel.core_plugins import MathPlugin, TimePlugin\n",
    "\n",
    "kernel.add_plugin(MathPlugin(), plugin_name=\"math\")\n",
    "kernel.add_plugin(TimePlugin(), plugin_name=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆã—ã¦ç™»éŒ²ã™ã‚‹\n",
    "\n",
    "ä»Šå›ã®ãƒãƒ£ãƒƒãƒˆã§ã¯ã€éå»ã®ä¼šè©±å±¥æ­´ï¼ˆchat_historyï¼‰ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ï¼ˆrequestï¼‰ã‚’çµ„ã¿åˆã‚ã›ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æº–å‚™ã—ã¾ã™ã€‚<br/>\n",
    "\"semantic-kernel\" å½¢å¼ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ã€ä¸¡æ–¹ã®æƒ…å ±ãŒåŸ‹ã‚è¾¼ã¾ã‚Œã‚‹ã‚ˆã†ã«è¨­å®šã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template import InputVariable, PromptTemplateConfig\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "\n",
    "template = \"\"\"\n",
    "Previous information from chat:\n",
    "{{$chat_history}}\n",
    "\n",
    "User: {{$request}}\n",
    "Assistant:\n",
    "\"\"\"\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=template,\n",
    "    name=\"chat\",\n",
    "    description=\"Chat with the assistant\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"chat_history\", description=\"The conversation history\", is_required=False, default=\"\"),\n",
    "        InputVariable(name=\"request\", description=\"The user's request\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=AzureChatPromptExecutionSettings(function_choice_behavior=\"auto\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernelï¼ˆã‚«ãƒ¼ãƒãƒ«ï¼‰ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ã£ã¦é–¢æ•°ã¨ã—ã¦ç™»éŒ²ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_function = kernel.add_function(\n",
    "    function_name=\"chat\",\n",
    "    plugin_name=\"ChatBot\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¼šè©±ã‚’é–‹å§‹ã—ã€AIã®å¿œç­”ã‚’å—ã‘å–ã‚‹\n",
    "\n",
    "ä¼šè©±ãƒ¬ãƒ™ãƒ«ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’é€ä¿¡ã—ã€Chat Completion APIã‹ã‚‰å¿œç­”ã‚’å–å¾—ã—ã¦å‡ºåŠ›ã—ã¾ã™ã€‚<br/>\n",
    "Kernelï¼ˆã‚«ãƒ¼ãƒãƒ«ï¼‰ã‚’å‘¼ã³å‡ºã™éš›ã¯ã€Kernel Argumentsã‚’ä½¿ã£ã¦å¼•æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ­ãƒ¼ã‚«ãƒ«ã®æ™‚é–“ã‚’å‡ºåŠ›ã—ã¦ã¿ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:28:27.09\n"
     ]
    }
   ],
   "source": [
    "!echo %time%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernelï¼ˆã‚«ãƒ¼ãƒãƒ«ï¼‰ã«ç™»éŒ²ã—ãŸã‚³ã‚¢ãƒ¼é–¢æ•°ã‚’Function Callingã«ã‚ˆã£ã¦å‘¼ã³å‡ºã•ã‚Œã‚‹ã‚ˆã†ã«ç¾åœ¨ã®æ™‚é–“ã‚’èã„ã¦ã¿ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello, how are you? I'm Jin, What time is it in Japan?\n",
      "Assistant: Hello Jin! I'm doing great, thank you. It's currently Saturday, March 8, 2025, 4:28 PM in Japan. How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.functions import KernelArguments\n",
    "user_input = \"Hello, how are you? I'm Jin, What time is it in Japan?\"\n",
    "answer = await kernel.invoke(\n",
    "    function=chat_function,\n",
    "    arguments=KernelArguments(\n",
    "        request=user_input,\n",
    "        chat_history=chat_history,\n",
    "    ),\n",
    ")\n",
    "print(\"User:\", user_input)\n",
    "chat_history.add_user_message(user_input)\n",
    "print(\"Assistant:\", answer)\n",
    "chat_history.add_assistant_message(str(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å±¥æ­´ã®ç¢ºèªã¨ã€æ•°å€¤è¨ˆç®—ã®ã‚³ã‚¢ãƒ¼é–¢æ•°ãŒFunction Callingã§å‘¼ã³å‡ºã•ã‚Œã‚‹ã‚ˆã†ã«èã„ã¦ã¿ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is my name? And what is the result of 100.00000001+100.000000000002?\n",
      "Assistant: Your name is Jin! ğŸ˜Š\n",
      "\n",
      "As for the calculation:\n",
      "\n",
      "\\(100.00000001 + 100.000000000002 = 200.000000010002\\)\n",
      "\n",
      "Let me know if you'd like more help!\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is my name? And what is the result of 100.00000001+100.000000000002?\"\n",
    "answer = await kernel.invoke(\n",
    "    function=chat_function,\n",
    "    arguments=KernelArguments(\n",
    "        request=user_input,\n",
    "        chat_history=chat_history,\n",
    "    ),\n",
    ")\n",
    "print(\"User:\", user_input)\n",
    "print(\"Assistant:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
