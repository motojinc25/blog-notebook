{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 環境を準備しよう\n",
    "https://github.com/microsoft/semantic-kernel/blob/main/python/samples/learn_resources/your_first_prompt.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、Semantic Kernelと必要なパッケージをインストールしてバージョンを確認ます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -qU semantic-kernel python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、Azure OpenAI Serviceのキー情報を保存している「.env」ファイルを読み込みます。\n",
    "`.env` ファイルには、次のような設定を記述します。\n",
    "\n",
    "```bash\n",
    "SK_AZURE_OPENAI_DEPLOYMENT_NAME=***\n",
    "SK_AZURE_OPENAI_API_KEY=***\n",
    "SK_AZURE_OPENAI_ENDPOINT=***\n",
    "SK_AZURE_OPENAI_API_VERSION=***\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この情報をコードで読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Tempalteを使って会話する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel（カーネル）を作成する\n",
    "\n",
    "Semantic Kernelのメインコンポーネントである Kernel（カーネル）のインスタンスを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIサービス（Azure OpenAI Service）を設定する\n",
    "\n",
    "Semantic Kernelでは、AIサービスを登録して使用します。<br/>\n",
    "ここでは、Azure OpenAI Serviceの GPT-4oモデルを利用し、[Chat Completion API](https://learn.microsoft.com/ja-jp/azure/ai-services/openai/how-to/chatgpt)を使います。<br/>\n",
    "サービスIDは必須ではありませんが、流れを理解しやすくするために設定しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "service_id = None\n",
    "chat_completion_service = AzureChatCompletion(\n",
    "    deployment_name = os.getenv(\"SK_AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_key = os.getenv(\"SK_AZURE_OPENAI_API_KEY\"),\n",
    "    endpoint = os.getenv(\"SK_AZURE_OPENAI_ENDPOINT\"), \n",
    "    api_version = os.getenv(\"SK_AZURE_OPENAI_API_VERSION\"), \n",
    "    service_id = service_id,\n",
    ")\n",
    "kernel.add_service(chat_completion_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チャット履歴を作成する\n",
    "\n",
    "チャットセッション内でメッセージ履歴を管理するために、チャット履歴オブジェクトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロンプトテンプレート作成して登録する\n",
    "\n",
    "チャット履歴とユーザ入力を設定できるプロンプトテンプレートを作成します。<br/>\n",
    "テンプレートには過去会話履歴と現在の入力が内容が入れる設定となっていてフォーマットは「Semantic Kernel」形式で作成しました。<br/>\n",
    "プロンプトテンプレートはプロンプトの設定オブジェクトで設定しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template import InputVariable, PromptTemplateConfig\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "\n",
    "template = \"\"\"\n",
    "Previous information from chat:\n",
    "{{$chat_history}}\n",
    "\n",
    "User: {{$request}}\n",
    "Assistant:\n",
    "\"\"\"\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=template,\n",
    "    name=\"chat\",\n",
    "    description=\"Chat with the assistant\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"chat_history\", description=\"The conversation history\", is_required=False, default=\"\"),\n",
    "        InputVariable(name=\"request\", description=\"The user's request\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=AzureChatPromptExecutionSettings(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel（カーネル）にプロンプトテンプレートを使って関数として登録します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_function = kernel.add_function(\n",
    "    function_name=\"chat\",\n",
    "    plugin_name=\"ChatBot\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 会話を開始し、AIの応答を受け取る\n",
    "\n",
    "会話レベルでユーザーの入力を送信し、Chat Completion APIから応答を取得して出力します。<br/>\n",
    "テンプレートで使いたい変数はKernelArgumentsオブジェクトとしてKernelに渡す必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello, how are you? I'm Jin\n",
      "Assistant: Hello Jin! I'm an AI language model, so I don't have feelings, but thanks for asking. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.functions import KernelArguments\n",
    "user_input = \"Hello, how are you? I'm Jin\"\n",
    "answer = await kernel.invoke(\n",
    "    function=chat_function,\n",
    "    arguments=KernelArguments(\n",
    "        request=user_input,\n",
    "        chat_history=chat_history,\n",
    "    ),\n",
    ")\n",
    "print(\"User:\", user_input)\n",
    "chat_history.add_user_message(user_input)\n",
    "print(\"Assistant:\", answer)\n",
    "chat_history.add_assistant_message(str(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次の内容を入力して会話を続けてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is my name?\n",
      "Assistant: Your name is Jin. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is my name?\"\n",
    "answer = await kernel.invoke(\n",
    "    function=chat_function,\n",
    "    arguments=KernelArguments(\n",
    "        request=user_input,\n",
    "        chat_history=chat_history,\n",
    "    ),\n",
    ")\n",
    "print(\"User:\", user_input)\n",
    "print(\"Assistant:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
